"use client";

import { strToU8 } from "fflate";

import { zipDeterministic } from "./deterministic_zip";
import { stableJsonText } from "./stable_json";

export type DeployLaneV1 = "vercel_template" | "vercel_github" | "vercel_cli" | "cloudflare" | "other";
export type DeployAiModeV1 = "offline" | "hosted" | "local";

export type DeployWizardStateV1 = {
  schema: "kindred.deploy_wizard.v1";
  project_id: string;
  updated_at_utc: string;
  lane: DeployLaneV1;
  ai_mode: DeployAiModeV1;

  // AI wiring (optional)
  openai_model?: string;
  openai_base_url?: string;
  // Secrets are never required for the wizard. If the user chooses to include them in an export,
  // they must provide them at export time (secrets are not persisted in-browser).
  include_secrets_in_export?: boolean;
};

const KEY_PREFIX = "kindred_deploy_wizard_v1:";

function key(projectId: string): string {
  return `${KEY_PREFIX}${String(projectId || "").trim() || "default"}`;
}

function safeJsonParse<T>(s: string): T | null {
  try {
    return JSON.parse(s) as T;
  } catch {
    return null;
  }
}

function normalize(raw: any, projectId: string): DeployWizardStateV1 {
  const pid = String(projectId || "").trim() || "default";
  const base: DeployWizardStateV1 = {
    schema: "kindred.deploy_wizard.v1",
    project_id: pid,
    updated_at_utc: new Date().toISOString(),
    lane: "vercel_template",
    ai_mode: "offline",
    openai_model: "gpt-4.1-mini",
    openai_base_url: "",
    include_secrets_in_export: false,
  };

  if (!raw || typeof raw !== "object") return base;
  if (raw.schema !== "kindred.deploy_wizard.v1") return base;

  const lane = raw.lane === "vercel_template" || raw.lane === "vercel_github" || raw.lane === "vercel_cli" || raw.lane === "cloudflare" || raw.lane === "other" ? raw.lane : base.lane;
  const ai_mode = raw.ai_mode === "offline" || raw.ai_mode === "hosted" || raw.ai_mode === "local" ? raw.ai_mode : base.ai_mode;

  const openai_model = typeof raw.openai_model === "string" ? raw.openai_model.trim().slice(0, 80) : base.openai_model;
  const openai_base_url = typeof raw.openai_base_url === "string" ? raw.openai_base_url.trim().slice(0, 240) : base.openai_base_url;

  const include_secrets_in_export = Boolean(raw.include_secrets_in_export);

  return {
    ...base,
    project_id: pid,
    lane,
    ai_mode,
    openai_model,
    openai_base_url,
    include_secrets_in_export,
    updated_at_utc: typeof raw.updated_at_utc === "string" ? raw.updated_at_utc : base.updated_at_utc,
  };
}

export function loadDeployWizardStateV1(projectId: string): DeployWizardStateV1 {
  const pid = String(projectId || "").trim() || "default";
  try {
    const raw = localStorage.getItem(key(pid));
    if (!raw) return normalize(null, pid);
    const parsed = safeJsonParse<any>(raw);
    return normalize(parsed, pid);
  } catch {
    return normalize(null, pid);
  }
}

function stripSecrets<T extends Record<string, any>>(x: T): T {
  if (!x || typeof x !== "object") return x;
  const y: any = { ...x };
  // Back-compat: never persist secrets (older builds may have stored openai_api_key).
  if (Object.prototype.hasOwnProperty.call(y, "openai_api_key")) delete y.openai_api_key;
  return y;
}

export function saveDeployWizardStateV1(projectId: string, patch: Partial<DeployWizardStateV1>): DeployWizardStateV1 {
  const pid = String(projectId || "").trim() || "default";
  const prev = loadDeployWizardStateV1(pid);
  const cleanPatch = stripSecrets(patch as any);
  const next: DeployWizardStateV1 = {
    ...stripSecrets(prev as any),
    ...cleanPatch,
    schema: "kindred.deploy_wizard.v1",
    project_id: pid,
    updated_at_utc: new Date().toISOString(),
  };
  try {
    localStorage.setItem(key(pid), stableJsonText(next));
  } catch {
    // ignore
  }
  return next;
}

function laneTitle(lane: DeployLaneV1): string {
  if (lane === "vercel_template") return "Vercel Deploy Template (fastest lane, minimal Git knowledge)";
  if (lane === "vercel_github") return "GitHub + Vercel (standard lane)";
  if (lane === "vercel_cli") return "Vercel CLI (local folder lane)";
  if (lane === "cloudflare") return "Cloudflare (free-first lane)";
  return "Other platform";
}

function envExample(state: DeployWizardStateV1, secrets?: { openai_api_key?: string }): string {
  const lines: string[] = [];
  lines.push("# Generated by Kindred Deploy Wizard (server-side env vars only)");
  lines.push("# Never prefix these values with NEXT_PUBLIC_.");
  lines.push("");

  if (state.ai_mode === "offline") {
    lines.push("AI_MODE=offline");
    lines.push("");
    lines.push("# Optional: enable hosted or local mode for proposal-only AI routes.");
    lines.push("# AI_MODE=hosted");
    lines.push("# OPENAI_API_KEY=replace_me");
    lines.push("# OPENAI_MODEL=gpt-4.1-mini");
    lines.push("#");
    lines.push("# AI_MODE=local");
    lines.push("# OPENAI_BASE_URL=http://localhost:1234/v1");
    lines.push("# AI_API_KEY=optional");
    lines.push("# AI_MODEL=gpt-4.1-mini");
    return lines.join("\n") + "\n";
  }

  if (state.ai_mode === "hosted") {
    lines.push("AI_MODE=hosted");
    const key = state.include_secrets_in_export ? String(secrets?.openai_api_key || "").trim() : "";
    lines.push(`OPENAI_API_KEY=${key ? key : "replace_me"}`);
    const model = String(state.openai_model || "").trim() || "gpt-4.1-mini";
    lines.push(`OPENAI_MODEL=${model}`);
    return lines.join("\n") + "\n";
  }

  // local
  lines.push("AI_MODE=local");
  const base = String(state.openai_base_url || "").trim() || "http://localhost:1234/v1";
  lines.push(`OPENAI_BASE_URL=${base}`);
  const key = state.include_secrets_in_export ? String(secrets?.openai_api_key || "").trim() : "";
  if (key) lines.push(`AI_API_KEY=${key}`);
  else lines.push("# AI_API_KEY=optional");
  const model = String(state.openai_model || "").trim() || "gpt-4.1-mini";
  lines.push(`AI_MODEL=${model}`);
  return lines.join("\n") + "\n";
}

function deployChecklistMarkdown(state: DeployWizardStateV1, projectName: string): string {
  const name = String(projectName || "project").trim() || "project";
  const lines: string[] = [];
  lines.push(`# Deploy checklist — ${name}`);
  lines.push("");
  lines.push(`**Lane:** ${laneTitle(state.lane)}`);
  lines.push(`**AI mode:** ${state.ai_mode}`);
  lines.push("");
  lines.push("This checklist is kernel-neutral. Platform-specific steps are optional and clearly marked.");
  lines.push("");
  lines.push("## 1) Produce the artefact");
  lines.push("- In Kindred: **Director → Ship** → follow gates → **Download locked Repo Pack**.");
  lines.push("- Keep the first ZIP you shipped. Store it as evidence (it contains provenance under `.kindred/`).");
  lines.push("");
  lines.push("## 2) Deploy (provider-neutral)");
  lines.push("- Unzip the repo pack locally.");
  lines.push("- Ensure Node >= 20 (per `package.json`).");
  lines.push("- Install dependencies: `npm install`.");
  lines.push("- Build: `npm run build`.");
  lines.push("- Start: `npm run start`.");
  lines.push("");
  lines.push("## 3) Optional lane steps");
  if (state.lane === "vercel_template") {
    lines.push("### Vercel (web UI, upload-first lane)");
    lines.push("- Create a new GitHub repo (public or private). You do not need to know git for this lane.");
    lines.push("- Upload the unzipped repo pack contents via GitHub’s web UI (Add file → Upload files).");
    lines.push("- In Vercel: New Project → Import Git Repository → select the repo → Deploy.");
    lines.push("- Default is safe: keep `AI_MODE=offline` and do not set any API keys.");
    lines.push("- If you enable AI later: set server-side env vars from `DEPLOYMENT/env.example` in *your* Vercel project.");
    lines.push("- See: `docs/vercel_deploy.md` (this repo).");
  } else if (state.lane === "vercel_github") {
    lines.push("### GitHub + Vercel (standard lane)");
    lines.push("- Push the repo to GitHub (git, GitHub Desktop, or your IDE).");
    lines.push("- In Vercel: import the repo (Next.js auto-detected).");
    lines.push("- Default is safe: keep `AI_MODE=offline` and do not set any API keys.");
    lines.push("- If enabling AI: set server-side env vars from `DEPLOYMENT/env.example` in *your* Vercel project.");
    lines.push("- See: `docs/vercel_deploy.md` (this repo).");
  } else if (state.lane === "vercel_cli") {
    lines.push("### Vercel CLI (local folder lane)");
    lines.push("- Install Vercel CLI (or use `npx vercel`).");
    lines.push("- From the unzipped repo pack folder: run `npx vercel` and follow prompts.");
    lines.push("- For production: `npx vercel --prod`.");
    lines.push("- Default is safe: keep `AI_MODE=offline` and do not set any API keys.");
    lines.push("- If enabling AI: add env vars from `DEPLOYMENT/env.example` in Vercel Project Settings or via `vercel env`.");
  } else if (state.lane === "cloudflare") {
    lines.push("### Cloudflare (optional free-first lane)");
    lines.push("- Deploy the repo using a Cloudflare-compatible workflow for Next.js.");
    lines.push("- Default is safe: keep `AI_MODE=offline` and do not set any API keys.");
    lines.push("- If enabling AI: set server-side env vars. (Provider specifics live in an optional Kit.)");
  } else {
    lines.push("### Other platform");
    lines.push("- Deploy the repo with your preferred host. The output is a standard Next.js repo.");
    lines.push("- Default is safe: keep `AI_MODE=offline` and do not set any API keys.");
  }
  lines.push("");
  lines.push("## 4) Debug (failure records)");

  lines.push("- If anything fails: copy the full build/deploy/runtime log.");
  lines.push("- In Kindred: **Director → Ship → Deploy & Debug** → paste log → **Save Failure Record**.");
  lines.push("- Optional: click **Ask AI for suggestions** (proposal-only). AI never silently edits.");
  lines.push("");
  return lines.join("\n") + "\n";
}

export function buildDeploymentPackZipV1(args: {
  project_id: string;
  project_name: string;
  state: DeployWizardStateV1;
  secrets?: { openai_api_key?: string };
}): Uint8Array {
  const pid = String(args.project_id || "").trim() || "default";
  const name = String(args.project_name || "").trim() || pid;
  const s = normalize(args.state, pid);

  const files: Record<string, Uint8Array> = {
    "DEPLOYMENT/deploy_config.v1.json": strToU8(stableJsonText({ ...s, project_name: name })),
    "DEPLOYMENT/env.example": strToU8(envExample(s, args.secrets)),
    "DEPLOYMENT/deploy_checklist.md": strToU8(deployChecklistMarkdown(s, name)),
  };

  return zipDeterministic(files, { level: 6 });
}
